{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76beb14a",
   "metadata": {},
   "source": [
    "# m_qubits_QVC_Breast_Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9115f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import svm\n",
    "\n",
    "import scipy\n",
    "from scipy.linalg import expm\n",
    "import scikitplot as skplt\n",
    "\n",
    "from h_partitioned import *\n",
    "#from W_unitary import *\n",
    "#from U_unitary import *\n",
    "from qiskit_algorithms.optimizers import COBYLA, ADAM, SPSA, SLSQP, POWELL, L_BFGS_B, TNC, AQGD\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (6,4)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7c0f5",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc64761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x1, x2, h=0.2):\n",
    "    \n",
    "    x1_min, x1_max = x1.min() - 1, x1.max() + 1\n",
    "    x2_min, x2_max = x2.min() - 1, x2.max() + 1\n",
    "    x1x1, x2x2 = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(x2_min, x2_max, h))\n",
    "    \n",
    "    return x1x1, x2x2\n",
    "\n",
    "\n",
    "def training_split(X_train, y_train, n_batches):\n",
    "    \n",
    "    if len(X_train)%n_batches == 0:\n",
    "        \n",
    "        X_batches = np.split(X_train, n_batches)\n",
    "        y_batches = np.split(y_train, n_batches)\n",
    "        \n",
    "    else:\n",
    "        print('Warning: the training set must be divided into equally sized batches')\n",
    "    \n",
    "    return X_batches, y_batches\n",
    "\n",
    "\n",
    "def k_fold_split(X, y, ele_per_split, i):\n",
    "    \n",
    "    k_X_train = np.concatenate( (X[:ele_per_split*i, :], X[ele_per_split*(i+1):, :]) )\n",
    "    k_X_test = X[ele_per_split*i:ele_per_split*(i+1), :]\n",
    "    \n",
    "    k_y_train = np.concatenate( (y[:ele_per_split*i], y[ele_per_split*(i+1):]) )\n",
    "    k_y_test = y[ele_per_split*i:ele_per_split*(i+1)]\n",
    "    \n",
    "    return k_X_train, k_X_test, k_y_train, k_y_test\n",
    "\n",
    "\n",
    "def PCA1(X_train, X_test, y_train, y_test, n_dimensions):\n",
    "    \n",
    "    # Now the dataset's features will be standardized\n",
    "    # to fit a normal distribution.\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # To be able to use this data with the given\n",
    "    # number of qubits, the data must be broken down from\n",
    "    # 30 dimensions to `n` dimensions.\n",
    "    # This is done with Principal Component Analysis (PCA),\n",
    "    # which finds patterns while keeping variation.\n",
    "    pca = PCA(n_dimensions).fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "    # The last step in the data processing is\n",
    "    # to scale the data to be between -1 and 1\n",
    "    samples = np.append(X_train, X_test, axis=0)\n",
    "    minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "    X_train = minmax_scale.transform(X_train)\n",
    "    X_test = minmax_scale.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def PCA2(X, y, n_dimensions):\n",
    "    \n",
    "    # Now the dataset's features will be standardized\n",
    "    # to fit a normal distribution.\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    # To be able to use this data with the given\n",
    "    # number of qubits, the data must be broken down from\n",
    "    # 30 dimensions to `n` dimensions.\n",
    "    # This is done with Principal Component Analysis (PCA),\n",
    "    # which finds patterns while keeping variation.\n",
    "    pca = PCA(n_dimensions).fit(X)\n",
    "    X = pca.transform(X)\n",
    "\n",
    "    # The last step in the data processing is\n",
    "    # to scale the data to be between -1 and 1\n",
    "    samples = X\n",
    "    minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "    X = minmax_scale.transform(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f12b2",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70612d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "\n",
    "used_points = 70 ## Must be multiple of 70\n",
    "\n",
    "X = dataset.data[:used_points]\n",
    "y = dataset.target[:used_points]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "n_dimensions = 4\n",
    "X_train, X_test, y_train, y_test = PCA1(X_train, X_test, y_train, y_test, n_dimensions)\n",
    "\n",
    "n_batches = 7 \n",
    "X_batches, y_batches = training_split(X_train, y_train, n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76507aa",
   "metadata": {},
   "source": [
    "## Classical SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5e969",
   "metadata": {},
   "source": [
    "### linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5274100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aglas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "linear_kernel = svm.LinearSVC()\n",
    "linear_kernel.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5df596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = linear_kernel.score(X_train, y_train)\n",
    "accuracy_test = linear_kernel.score(X_test, y_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345fe64",
   "metadata": {},
   "source": [
    "### gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a88a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel = svm.SVC(gamma = 'scale')\n",
    "gaussian_kernel.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9890eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = gaussian_kernel.score(X_train, y_train)\n",
    "accuracy_test = gaussian_kernel.score(X_test, y_test)\n",
    "\n",
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603996e3",
   "metadata": {},
   "source": [
    "## Quantum SVM (explicit approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbeba259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters: [2.35330497 5.97351416 4.59925358 3.76148219 0.98029403 0.98014248\n",
      " 0.3649501  5.44234523 3.77691701 4.44895122 0.12933619 6.09412333\n",
      " 5.23039137 1.33416598 1.14243996 1.15236452 1.91161039 3.2971419\n",
      " 2.71399059 1.82984665 3.84438512 0.87646578 1.83559896 2.30191935]\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "seed = np.random.seed(RANDOM_STATE)\n",
    "\n",
    "n = 4\n",
    "d = 2\n",
    "n_part = 2\n",
    "\n",
    "init_theta = 2*np.pi*np.random.random(n*d*3)\n",
    "print('Initial parameters: '+ str(init_theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80494259",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bb32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(theta, data, labels):\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(0, len(labels)):\n",
    "        if labels[i] == 0:\n",
    "            tmp.append(-1)\n",
    "        else:\n",
    "            tmp.append(1)\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(0, len(labels)):\n",
    "        predictions.append(h_partitioned(data[i], n, n_part, d, shots, theta))\n",
    "    \n",
    "    error = []\n",
    "    for i in range(0, len(predictions)):\n",
    "        parity = predictions[i] - tmp[i]\n",
    "        error.append(parity)\n",
    "\n",
    "    norm = np.linalg.norm(error)\n",
    "    \n",
    "    return norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a606297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(j)\n\u001b[1;32m---> 17\u001b[0m     prediction[j] \u001b[38;5;241m=\u001b[39m \u001b[43mh_partitioned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_part\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     objective_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m theta: MSE_loss(theta, data, labels)\n\u001b[0;32m     20\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m COBYLA(maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aglas\\Local_Documents\\GitHub\\QPQC_Project\\h_partitioned.py:287\u001b[0m, in \u001b[0;36mh_partitioned\u001b[1;34m(x, n, n_part, d, shots, theta)\u001b[0m\n\u001b[0;32m    284\u001b[0m         circuit2\u001b[38;5;241m.\u001b[39mmeasure(\u001b[38;5;28mrange\u001b[39m(n_part),\u001b[38;5;28mrange\u001b[39m(n_part))\n\u001b[0;32m    286\u001b[0m         expectation_1 \u001b[38;5;241m=\u001b[39m expectation(circuit1,shots)\n\u001b[1;32m--> 287\u001b[0m         expectation_2 \u001b[38;5;241m=\u001b[39m \u001b[43mexpectation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m         expectation_value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m expectation_1\u001b[38;5;241m*\u001b[39mexpectation_2\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expectation_value \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aglas\\Local_Documents\\GitHub\\QPQC_Project\\h_partitioned.py:8\u001b[0m, in \u001b[0;36mexpectation\u001b[1;34m(circuit, shots)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexpectation\u001b[39m(circuit,shots):\n\u001b[0;32m      7\u001b[0m     simulator \u001b[38;5;241m=\u001b[39m Aer\u001b[38;5;241m.\u001b[39mget_backend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maer_simulator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     counts \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_counts()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#Get keys of dictionary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aglas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\qiskit_aer\\jobs\\utils.py:42\u001b[0m, in \u001b[0;36mrequires_submit.<locals>._wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_future \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob not submitted yet!. You have to .submit() first!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aglas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\qiskit_aer\\jobs\\aerjob.py:114\u001b[0m, in \u001b[0;36mAerJob.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@requires_submit\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get job result. The behavior is the same as the underlying\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    concurrent Future objects,\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m        concurrent.futures.CancelledError: if job cancelled before completed.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aglas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\aglas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = n_batches\n",
    "shots = 1024\n",
    "theta = init_theta\n",
    "thetas = []\n",
    "predictions = []\n",
    "training_accuracies = []\n",
    "testing_accuracies = []\n",
    "\n",
    "for i in tqdm(range(0, epochs)):\n",
    "    \n",
    "    prediction = np.zeros(len(y_batches[i]))\n",
    "    data = X_batches[i]\n",
    "    labels = y_batches[i]\n",
    "    \n",
    "    for j in range(0, len(data)):\n",
    "        print(j)\n",
    "        prediction[j] = h_partitioned(data[j], n, n_part, d, shots, theta)\n",
    "        \n",
    "        objective_function = lambda theta: MSE_loss(theta, data, labels)\n",
    "        optimizer = COBYLA(maxiter=100)\n",
    "        \n",
    "        theta_opt = optimizer.minimize(objective_function, theta).x\n",
    "    \n",
    "    h_subtest = np.zeros(len(y_test))\n",
    "    for j in range(0, len(y_test)):\n",
    "        h_subtest[j] = h_partitioned(X_test[j], n, n_part, d, shots, theta_opt)\n",
    "    \n",
    "    train_result = 1 - ( ((sum(np.abs(2*labels-1-prediction)))/2) / len(labels) ) \n",
    "    test_result = 1 -  ( ((sum(np.abs(2*y_test-1-h_subtest)))/2) / len(y_test) ) \n",
    "    training_accuracies.append(train_result)\n",
    "    testing_accuracies.append(test_result)\n",
    "    \n",
    "    thetas.append(theta_opt)\n",
    "    predictions.append(prediction)\n",
    "    theta = theta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75413c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracies: '+ str(training_accuracies))\n",
    "print('Training mean: '+ str(np.mean(training_accuracies)))\n",
    "print('Testing accuracies: '+ str(testing_accuracies))\n",
    "print('Testing mean: '+ str(np.mean(testing_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d89ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(training_accuracies, color='blue', label='training')\n",
    "plt.plot(testing_accuracies, color='red', linestyle=':',label='testing')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracies')\n",
    "plt.legend(loc=0, frameon=False)\n",
    "plt.savefig('BC_learning_partitioned.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d41a45",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(0, len(predictions)):\n",
    "    for j in range(0, len(predictions[i])):\n",
    "        tmp.append(predictions[i][j])\n",
    "        \n",
    "accuracy_train = 1 - ( ((sum(np.abs(2*y_train-1-tmp)))/2) / len(y_train) )\n",
    "print('Training accuracy: '+ str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab20d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test = []\n",
    "for i in range(0, len(y_test)):\n",
    "    h_test.append(h_partitioned(X_test[i], n, n_part, d, shots, theta_opt))\n",
    "\n",
    "accuracy_test = 1 - ( ((sum(np.abs(2*y_test-1-h_test)))/2) / len(y_test) ) \n",
    "print('Testing accuracy: '+ str(accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30868c6b",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1e700",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "assert len(X)%k == 0 \n",
    "ele_per_split = int(len(X)/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bc3a8",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = init_theta\n",
    "k_thetas = []\n",
    "k_training_accuracies = []\n",
    "k_testing_accuracies = []\n",
    "\n",
    "for i in tqdm(range(k)):\n",
    "    \n",
    "    k_X_train, k_X_test, k_y_train, k_y_test = k_fold_split(X, y, ele_per_split, i)\n",
    "    k_X_train, k_X_test, k_y_train, k_y_test = PCA1(k_X_train, k_X_test, k_y_train, k_y_test, n_dimensions)\n",
    "\n",
    "    objective_function = lambda theta: MSE_loss(theta, k_X_train, k_y_train)\n",
    "    optimizer = COBYLA(maxiter=100)\n",
    "    \n",
    "    theta_opt = optimizer.minimize(objective_function, theta).x\n",
    "\n",
    "    k_thetas.append(theta_opt)\n",
    "\n",
    "    k_train_predictions = np.zeros(len(k_y_train))\n",
    "    for j in range(0, len(k_y_train)):\n",
    "        k_train_predictions[j] = h_partitioned(k_X_train[j], n, n_part, d, shots, theta_opt) \n",
    "\n",
    "    k_test_predictions = np.zeros(len(k_y_test))\n",
    "    for j in range(0, len(k_y_test)):\n",
    "        k_test_predictions[j] = h_partitioned(k_X_test[j], n, n_part, d, shots, theta_opt) \n",
    "        \n",
    "    k_train_result = 1 - ( ((sum(np.abs(2*k_y_train-1-k_train_predictions)))/2) / len(k_y_train) )\n",
    "    k_test_result = 1 - ( ((sum(np.abs(2*k_y_test-1-k_test_predictions)))/2) / len(k_y_test) )\n",
    "    k_training_accuracies.append(k_train_result)\n",
    "    k_testing_accuracies.append(k_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracies: '+ str(k_training_accuracies))\n",
    "print('Training mean: '+ str(np.mean(k_training_accuracies)))\n",
    "print('Testing accuracies: '+ str(k_testing_accuracies))\n",
    "print('Testing mean: '+ str(np.mean(k_testing_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_training_accuracies, color='blue', label='training')\n",
    "plt.plot(k_testing_accuracies, color='red', linestyle=':',label='testing')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracies')\n",
    "plt.legend(loc=0, frameon=False)\n",
    "plt.savefig('BC_cv_partitioned.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb4064",
   "metadata": {},
   "source": [
    "### valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_testing_accuracy = max(k_testing_accuracies)\n",
    "index = k_testing_accuracies.index(max_testing_accuracy)\n",
    "k_theta_opt = k_thetas[index]\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_val = dataset.data[:used_points]\n",
    "y_val = dataset.target[:used_points]\n",
    "\n",
    "X_val, y_val = PCA2(X_val, y_val, n_dimensions)\n",
    "\n",
    "h_val = np.zeros(len(y_val))\n",
    "for i in range(0, len(y_val)):\n",
    "    h_val[i] = h_partitioned(X_val[i], n, n_part, d, shots, k_theta_opt) \n",
    "\n",
    "validation_accuracy = 1 - ( ((sum(np.abs(2*y_val-1-h_val)))/2) / len(y_val) )\n",
    "\n",
    "print(\"Optimal parameters: \"+ str(k_theta_opt))\n",
    "print(\"Validation accuracy: \"+ str(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(0, len(h_val)):\n",
    "    if h_val[i] == 1:\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        tmp.append(1)\n",
    "        \n",
    "skplt.metrics.plot_confusion_matrix(y_val, tmp, normalize=True, title = 'Breast Cancer (after cross-validation)');\n",
    "plt.savefig('BC_cf_partitioned.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a94f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
