{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-9b0f1830d79c>:14: DeprecationWarning: ``qiskit.algorithms`` has been migrated to an independent package: https://github.com/qiskit-community/qiskit-algorithms. The ``qiskit.algorithms`` import path is deprecated as of qiskit-terra 0.25.0 and will be removed no earlier than 3 months after the release date. Please run ``pip install qiskit_algorithms`` and use ``import qiskit_algorithms`` instead.\n",
      "  from qiskit.algorithms.optimizers import COBYLA, ADAM, SPSA, SLSQP, POWELL, L_BFGS_B, TNC, AQGD\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import make_blobs \n",
    "from sklearn import svm\n",
    "\n",
    "from h import *\n",
    "from W_unitary import *\n",
    "from U_unitary import *\n",
    "from qiskit.algorithms.optimizers import COBYLA, ADAM, SPSA, SLSQP, POWELL, L_BFGS_B, TNC, AQGD\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.rcParams['figure.figsize'] = (10,6)\n",
    "#plt.rcParams['figure.dpi'] = 100\n",
    "#sns.set()\n",
    "\n",
    "#%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(theta, X_train, y_train):\n",
    "    \n",
    "    # new_y_train = []\n",
    "    # for i in range(0, len(y_train)):\n",
    "    #     if y_train[i] == 0:\n",
    "    #         new_y_train.append(-1)\n",
    "    #     else:\n",
    "    #         new_y_train.append(1)\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(0, len(y_train)):\n",
    "        predictions.append(h(X_train[i], theta, 2, 2, shots))\n",
    "    \n",
    "    error = []\n",
    "    for i in range(0, len(predictions)):\n",
    "        parity = predictions[i] - y_train[i]\n",
    "        error.append(parity)\n",
    "\n",
    "    norm = np.linalg.norm(error)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def k_fold_split(X, y, ele_per_split, i):\n",
    "    \n",
    "    X_train =  np.concatenate( (X[:ele_per_split*i, :], X[ele_per_split*(i+1):, :]) )\n",
    "    X_test = X[ele_per_split*i:ele_per_split*(i+1), :]\n",
    "    \n",
    "    y_train = np.concatenate( (y[:ele_per_split*i], y[ele_per_split*(i+1):]) )\n",
    "    y_test = y[ele_per_split*i:ele_per_split*(i+1)]\n",
    "    \n",
    "    return X_train, X_test, 2*y_train-1, 2*y_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=42\n",
    "seed = np.random.seed(RANDOM_STATE)\n",
    "\n",
    "n = 2\n",
    "d = 2\n",
    "theta = 2*np.pi*np.random.random(n*d*3)\n",
    "\n",
    "n_samples = 100\n",
    "noise = 0.3\n",
    "k = 4\n",
    "if n_samples%k != 0:\n",
    "    print(\"Prefered to have k as a divisor of n_samples\")\n",
    "ele_per_split = n_samples//k\n",
    "\n",
    "X, y = make_moons(n_samples, noise=noise)\n",
    "\n",
    "shots = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 1/4 [00:59<02:58, 59.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  1\n",
      "Optimal parameters:  [2.18635173 5.91048939 4.284906   3.59462312 0.5242556  0.66558844\n",
      " 0.24681434 4.72776911 3.46253916 4.28224945 0.1777993  5.77942507]\n",
      "Training accuracy:  29 incorrectly out of  75\n",
      "Testing accuracy:  13.0 incorrectly out of  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 2/4 [02:04<02:05, 62.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  2\n",
      "Optimal parameters:  [3.17887253 7.16681958 4.58984355 3.67524516 0.86966649 1.04895217\n",
      " 0.77480851 6.13784075 3.77303594 4.44507015 0.12545513 6.09412333]\n",
      "Training accuracy:  29 incorrectly out of  75\n",
      "Testing accuracy:  10.0 incorrectly out of  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [03:05<01:01, 61.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  3\n",
      "Optimal parameters:  [3.35332145 6.97351461 4.59920414 3.76147939 0.98028306 0.98010904\n",
      " 0.36494313 5.44240343 3.77696203 4.44897234 0.12932479 6.09412333]\n",
      "Training accuracy:  32 incorrectly out of  75\n",
      "Testing accuracy:  13.0 incorrectly out of  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [04:06<00:00, 61.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  4\n",
      "Optimal parameters:  [ 2.35330497  5.97351416  4.59925358  3.76148219  2.34701663  0.61341988\n",
      "  2.11400598  5.06514168  3.02786113  4.18094998 -0.98644229  6.09412333]\n",
      "Training accuracy:  30 incorrectly out of  75\n",
      "Testing accuracy:  15.0 incorrectly out of  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thetas = np.zeros((len(theta), k))\n",
    "\n",
    "for i in tqdm(range(k)):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = k_fold_split(X, y, ele_per_split, i)\n",
    "\n",
    "    objective_function = lambda theta: MSE_loss(theta, X_train, y_train)\n",
    "\n",
    "    optimizer = COBYLA(maxiter=100)\n",
    "    theta_opt = optimizer.minimize(objective_function, theta).x\n",
    "\n",
    "    thetas[:, i] = theta_opt\n",
    "\n",
    "    y_optimizer_train = np.zeros(len(y_train))\n",
    "    for j in range(0, len(y_train)):\n",
    "        y_optimizer_train[j] = ( h(X_train[j], theta_opt, n, d, shots) )\n",
    "\n",
    "    y_optimizer_test = np.zeros(len(y_test))\n",
    "    for j in range(0, len(y_test)):\n",
    "        y_optimizer_test[j] = ( h(X_test[j], theta_opt, n, d, shots) )\n",
    "    \n",
    "    #training_accuracy = (int(1/2*np.sum(abs(y_optimizer_train-y_train))) / n_samples - n_samples//k) * 100\n",
    "    #testing_accuracy = (1/2*np.sum(abs(y_optimizer_test-y_test)) / n_samples//k) * 100\n",
    "    print(\"Split: \", i+1)\n",
    "    print(\"Optimal parameters: \", theta_opt)\n",
    "    print(\"Training accuracy: \", int(1/2*np.sum(abs(y_optimizer_train-y_train))), \"incorrectly out of \", n_samples - n_samples//k)\n",
    "    print(\"Testing accuracy: \", 1/2*np.sum(abs(y_optimizer_test-y_test)), \"incorrectly out of \", n_samples//k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 103.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal average parameters:  [ 2.76796267  6.50608443  4.51830182  3.69820746  1.18030544  0.82701738\n",
      "  0.87514299  5.34328874  3.51009956  4.33931048 -0.13846577  6.01544877]\n",
      "Validation accuracy:  11.0 incorrectly out of  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "theta_opt_avg = np.mean(thetas, axis=1)\n",
    "X_val, y_val = make_moons(n_samples//k, noise=noise)\n",
    "\n",
    "y_val = 2*y_val-1\n",
    "y_optimizer_val = np.zeros(len(y_val))\n",
    "for j in tqdm(range(0, len(y_val))):\n",
    "    y_optimizer_val[j] = ( h(X_val[j], theta_opt, n, d, shots) )\n",
    "\n",
    "#validation_accuracy = (1/2*np.sum(abs(y_optimizer_val-y_val)) / n_samples//k) * 100\n",
    "print(\"Optimal average parameters: \", theta_opt_avg)\n",
    "print(\"Validation accuracy: \", 1/2*np.sum(abs(y_optimizer_val-y_val)), \"incorrectly out of \", n_samples//k)\n",
    "\n",
    "#print(sum(y_val!=y_optimizer_val))\n",
    "# print(y_val)\n",
    "# print(y_optimizer_val)\n",
    "# print(y_val==y_optimizer_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
